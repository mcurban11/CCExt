---
title: "Overall model of extinction risk from climate change"
output: word_document
date: "Jan. 5, 2024"
---

```{r, libraries and data, results='hide', message = F}
knitr::opts_chunk$set(echo = TRUE, cache.lazy = FALSE) 
rm(list = ls())
 root.dir = "C:/Users/mcu08001/Documents/1New Research/CC MetaRisk2/Analysis"
library(MCMCglmm); library(coda); library(ggplot2); library(rstan); library(bayesplot); library(shinystan); library(loo); library(rstanarm);

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = FALSE)
dataP<-read.table("Metarisk2 aggthres 5.txt",header=T); #newest data with slight fix to dispersal data

"number of unique studies"
length(unique(dataP$Study))

dataP2<-dataP[is.finite(dataP$Pre.Ind.Rise),]; attach(dataP2) # need to eliminate NA s for pre-industrial rise or stat programs crash

#Bayesian stan model proportional and weighted
#betareg requires no 0s or 1s
koffset = 0.001 #the k that gives the best posterior predictive check
percent2 <- adj.percent
percent2[adj.percent == 0] = koffset;
percent2[adj.percent == 1] = 1 - koffset;
dataP2$percent2 <- percent2;

data.use<-dataP2

N = length(data.use$percent2)
n.Study <- length(unique(data.use$Study)) #number of studies
Studyint<-as.integer(unclass(factor(data.use$Study)))
phi = data.use$Total.N
P.Ind<-seq(from = 0.4, to = 5.5,by = .1) #don't extrapolate rise  min(Pre.Ind.Rise)= 0.4

stan.data<-list(N = N, percent = data.use$percent2, Ind = data.use$Pre.Ind.Rise, phi = phi, S = n.Study, Study = Studyint)
params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")
params.to.monitor2=c("mu","beta")#
```

```{r baseline analysis}
# mod=stan(file="MetaRisk2 RSTAN betareg 2b.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=7000, cores=7,iter=10000,
#          control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2pre_lowb.rds") #mu prior (-50,1)
modx = mod

sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 
#ggsave("Fig S1b koffset 001.png",width=8,height=5.5,unit="in",dpi="print") #offset = 0.001
#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
```

# Intercept-only model
Subset of studies with pre-industrial data 

```{r intercept only}
#Intercept only model, for subset of studies with pre-ind temp data
# mod=stan(file="MetaRisk2 RSTAN int only 1.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=3,iter=8000, save_warmup = FALSE,
#          init = init.fn, control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2sub_interc.rds")
params.to.monitor2=c("mu")#

sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 
#ggsave("Fig S1b koffset 001.png",width=8,height=5.5,unit="in",dpi="print") #offset = 0.001
#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
```


```{r Fig 1, message = F, warning=FALSE}
#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line = pred.reg.quant[2,],
                          low_line = pred.reg.quant[1,],
                          hi_line = pred.reg.quant[3,])

#parameter plot with intervals
params.to.show=c("mu","beta")
mcmc_intervals(posterior,prob=.8,prob_outer = .95,pars=params.to.show)

Fig1<-ggplot(data = pred.reg.df)+
  stat_density2d(data = data.use, aes(x=Pre.Ind.Rise, y=percent2, fill = ..density..^.5), 
                 geom = "tile", contour = FALSE, n = 200, show.legend = FALSE, alpha = .8) +
  scale_fill_continuous(low = "white", high = "#5485A0") +
  geom_point(data = data.use, aes(x=Pre.Ind.Rise, y=percent2, size = log(Total.N)), alpha = 0.6, shape = 20, color = "#5485A0") +
  geom_ribbon(data = pred.reg.df, aes(x=P.Ind,ymin=low_line,ymax=hi_line),alpha=.2,fill="darkred") +
  geom_line(data = pred.reg.df, aes(x=P.Ind,y=mean_line),size=3,color="darkred") +
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk") +
  theme_classic()+ ylim(0,1) +  scale_x_continuous(breaks = seq(0,5,1), limits = c(0,5.5)) + #xlim(0,6) + 
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig1

#ggsave("FigS1 full preind.png",width=8,height=6,unit="in",dpi="print")

#-----------------------
#does not show full y axis for display
Fig1b<-ggplot(data = pred.reg.df)+
  stat_density2d(data = data.use, aes(x=Pre.Ind.Rise, y=percent2, fill = ..density..^.5), 
                 geom = "tile", contour = FALSE, n = 200, show.legend = FALSE, alpha = .8) +
  scale_fill_continuous(low = "white", high = "#5485A0") +
  geom_point(data = data.use, aes(x=Pre.Ind.Rise, y=percent2, size = log(Total.N)), alpha = 0.6, shape = 20, color = "#5485A0") +
  geom_ribbon(data = pred.reg.df, aes(x=P.Ind,ymin=low_line,ymax=hi_line),alpha=.2,fill="darkred") +
  geom_line(data = pred.reg.df, aes(x=P.Ind,y=mean_line),size=3,color="darkred") +
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk") +
  theme_classic() + scale_x_continuous(breaks = seq(0,5,1), limits = c(0,5.5)) + scale_y_continuous(breaks = seq(0,.35,0.05), limits = c(0,.35)) +
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig1b

#ggsave("FigS1b ylim preind.png",width=8,height=6,unit="in",dpi="print")
```

```{r LOO table 1, cache = TRUE}
load("2pre_lowb.rds")
loo.mod2=loo.mod # rename loo.mod so can load n
mod2 = mod
load("2sub_interc.rds") #intercept only model

table.data<-data.frame(
  Model = c("Intercept-only model","Baseline model"),
  LOOic = c(loo.mod$estimates[3],loo.mod2$estimates[3]),
  SE = c(loo.mod$estimates[6],loo.mod2$estimates[6])
)
knitr::kable(table.data, caption = "Table x: Comparisons of LOOic between intercept-only and baseline models", format = "markdown")
Looic.diff = loo.mod2$estimates[3] - loo.mod$estimates[3]
cat("difference in LOOic =", Looic.diff)
```

#LOOic comparison The model with climate change is 289.1 less, and thus a better supported model.

```{r linear analysis - no mu restriction}
# params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")
# mod=stan(file="MetaRisk2 RSTAN betareg.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=3,iter=8000, save_warmup = FALSE,
#          control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2pre_low.rds") #mu prior (-50,5),less restriction on ~0 intercept

params.to.monitor2=c("mu","beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 

loo.mod # 
```

```{r Fig 2, cache=TRUE}
load("2pre_low.rds") #all non-proportionate analysis
modx = mod

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_2 = pred.reg.quant[2,],
                          low_line_2 = pred.reg.quant[1,],
                          hi_line_2= pred.reg.quant[3,])

load("2pre_lowb.rds")
mod2 = mod
posterior=as.data.frame(mod2); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_base = pred.reg.quant[2,]
pred.reg.df$low_line_base = pred.reg.quant[1,]
pred.reg.df$hi_line_base= pred.reg.quant[3,]

Fig3<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_2,ymax=hi_line_2),alpha=.7,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_2),size=1.5,color="#154c8e")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig3

#ggsave("Fig Sx preind less inf zero.png",width=8,height=5.5,unit="in",dpi="print")
```
#Comparing models with weakly (blue) and strongly (red) informed priors on a zero intercept.
The weakly informed model suggests a slightly higher extinction risk and a less realistic extinction risk at zero temperature, but the two results largely overlapped.

```{r quadratic analysis, cache=TRUE}
#create model matrix for coefficients
betamat=model.matrix(~-1+data.use$Pre.Ind.Rise + I(data.use$Pre.Ind.Rise^2))

stan.data<-list(N = N, percent = data.use$percent2, betamat = betamat, phi = phi, S = n.Study, P = ncol(betamat), Study = Studyint)
params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")

init.fn<- function (chain_id) {
  list(mu = -5, beta = c(0.5,0))
}

# mod=stan(file="MetaRisk2 RSTAN quad 2.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=7,iter=8000,
#          init = init.fn, control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2poly2b.rds")

params.to.monitor2=c("mu","beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 

#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
```

```{r polynomial looic analysis, cache=TRUE}
##create data frame of looics from two models
load("2pre_lowb.rds")
loo.mod2=loo.mod # rename loo.mod so can load n

load("2poly2b.rds")

table.data<-data.frame(
  Model = c("Baseline model","Polynommial model"),
  LOOic = c(loo.mod$estimates[3],loo.mod2$estimates[3]),
  SE = c(loo.mod$estimates[6],loo.mod2$estimates[6])
)
knitr::kable(table.data, caption = "Table x: Comparisons of LOOic between linear and quadratic models") #, format = "simple"
Looic.diff = loo.mod$estimates[3] - loo.mod2$estimates[3]
cat("Difference in LOOic = ", Looic.diff)
```

Results Although the quadratic coefficient does not overlap zero, the overall model is worse as determined by the increase in LOOic = +6.4.

```{r Fig polynomial, cache=TRUE}
P.Ind<-seq(from = 0.4, to = 5.5,by = .1) 

load("2pre_lowb.rds") #
modx = mod

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_base = pred.reg.quant[2,],
                          low_line_base = pred.reg.quant[1,],
                          hi_line_base= pred.reg.quant[3,])

load("2poly2b.rds") 
mod2 = mod
params.to.monitor2=c("beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

posterior=as.data.frame(mod2); 
mu<-posterior[["mu"]]
beta1<-posterior[["beta[1]"]]
beta2<-posterior[["beta[2]"]]

# mu<-posterior[["beta[1]"]]
# beta1<-posterior[["beta[2]"]]
# beta2<-posterior[["beta[3]"]]

pred.reg = sapply(1:length(mu), FUN = function(x) {mu[x] + beta1[x]*P.Ind} + beta2[x]*P.Ind^2)
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_quad = pred.reg.quant[2,]
pred.reg.df$low_line_quad = pred.reg.quant[1,]
pred.reg.df$hi_line_quad= pred.reg.quant[3,]

Fig2<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_quad,ymax=hi_line_quad),alpha=.7,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_quad),size=1.5,color="#154c8e")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig2

#ggsave("Fig Sx preind poly.png",width=8,height=5.5,unit="in",dpi="print")
```

```{r unaggregated analysis, cache=TRUE}
#Bayesian stan model weighted, not aggregated data
rm(list = ls())
data <- read.table("MetaRisk for aggreg 5.txt",header=T); attach(data)
dataP1<-data[is.finite(data$Pre.Ind.Rise),]; attach(dataP1) # need to eliminate NA s for pre-industrial rise or stat programs crash

#betareg requires no 0s or 1s
koffset = 0.001
percent2 <- percent
percent2[percent == 0] = koffset;
percent2[percent == 1] = 1 - koffset;
dataP1$percent2 <- percent2;
data.use<-dataP1

N = length(data.use$percent)
n.Study <- length(unique(data.use$Study)) #number of studies
Studyint<-as.integer(unclass(factor(data.use$Study)))
phi = data.use$Total.N

stan.data<-list(N = N, percent = data.use$percent2, Ind = data.use$Pre.Ind.Rise, phi = phi, S = n.Study, Study = Studyint)
params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")

init.fn<- function (chain_id) {
  list(mu = -4.5, beta = 0.5)
}

# mod=stan(file="MetaRisk2 RSTAN betareg 2b.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=3,iter=8000, save_warmup = FALSE,
#          control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2noagg.rds")

params.to.monitor2=c("mu","beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 

#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
```

```{r Fig 3, cache=TRUE}
load("2noagg.rds") #all non-proportionate analysis
modx = mod
P.Ind<-seq(from = 0.4, to = 5.5,by = .1) #don't extrapolate rise  min(Pre.Ind.Rise)= 0.4

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_all = pred.reg.quant[2,],
                          low_line_all = pred.reg.quant[1,],
                          hi_line_all= pred.reg.quant[3,])

load("2pre_lowb.rds")
mod2 = mod
posterior=as.data.frame(mod2); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_base = pred.reg.quant[2,]
pred.reg.df$low_line_base = pred.reg.quant[1,]
pred.reg.df$hi_line_base= pred.reg.quant[3,]

Fig3<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_all,ymax=hi_line_all),alpha=.7,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_all),size=1.5,color="#154c8e")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig3

#ggsave("Fig Sx preind nonprop.png",width=8,height=5.5,unit="in",dpi="print")
```

##Comparing all data beta analysis to proportionate beta analysis As expected, the beta regression that uses all data produces a lower prediction than the beta regression based on predictions proportionate to extinction risk. The reasoning is that the former method averages predictions across range loss scenarios, usually 80%, 95%, and 100%, and thus predicts extinction risk at \~ 92%. The latter, and at least in my mind preferred, method sets risk proportional to range loss. For example, if out of 10 species, 5 face extinction at 80% range loss, 2 at 95% range loss, and 1 at 100% range loss, the averaged method would suggest a predicted risk of (5 + 2 +1)/3x10 = 30%, and provides a highly conservative estimate especially if most range losses are between 80 - 95%. A proportionate analysis would suggest a predicted risk of [.8(5-1-1) + .95(2-1) + 1(1)]/10 = 44%. Given that many scientists would use the 80% range loss criterion to define future extinction risk and that this category includes range losses from 80-95%, I think that the proportionate response is still being conservative.

```{r proportional analysis unweighted, cache=TRUE}
#Bayesian stan model proportional and weighted
dataP<-read.table("Metarisk2 aggthres 5.txt",header=T); 
dataP2<-dataP[is.finite(dataP$Pre.Ind.Rise),]; attach(dataP2) # need to eliminate NA s for pre-industrial rise or stat programs crash

#betareg requires no 0s or 1s
koffset = 0.001 #the k that gives the best posterior predictive check
percent2 <- adj.percent
percent2[adj.percent == 0] = koffset;
percent2[adj.percent == 1] = 1 - koffset;
dataP2$percent2 <- percent2;

data.use<-dataP2

N = length(data.use$percent2)
n.Study <- length(unique(data.use$Study)) #number of studies
Studyint<-as.integer(unclass(factor(data.use$Study)))

stan.data<-list(N = N, percent = data.use$percent2, Ind = data.use$Pre.Ind.Rise, S = n.Study, Study = Studyint)
params.to.monitor=c("mu","beta","phi","y_rep","stu","sigma_stu", "eta","log_lik")

# mod=stan(file="MetaRisk2 RSTAN betareg notwtd 5.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=7000, cores=3,iter=10000, save_warmup = FALSE,
#          control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2pre_nowt5b.rds")

params.to.monitor2=c("mu","beta","phi")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 

#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 

```

```{r Fig 4, cache=TRUE}
load("2pre_nowt5b.rds") #all non-proportionate analysis
modx = mod

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_unwt = pred.reg.quant[2,],
                          low_line_unwt = pred.reg.quant[1,],
                          hi_line_unwt = pred.reg.quant[3,])

load("2pre_lowb.rds")
mod2 = mod
posterior=as.data.frame(mod2); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_base = pred.reg.quant[2,]
pred.reg.df$low_line_base = pred.reg.quant[1,]
pred.reg.df$hi_line_base= pred.reg.quant[3,]

Fig4<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_unwt,ymax=hi_line_unwt),alpha=.7,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_unwt),size=1.5,color="#154c8e")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig4

#ggsave("Fig S3 preind unwtd.png",width=8,height=5.5,unit="in",dpi="print")
```

#Comparing unweighted (blue) vs. weighted (red) proportional analyses Without weighting the predictions, the estimated relationship with temperature rise is lower than the version weighted by beta variance (total N). Also, the unweighted version suggests a smaller intercept. The unweighted version overestimates the number of zeros (see posterior check).

```{r main proportional analysis with larger koffset, cache=TRUE}
#Bayesian stan model proportional and weighted
#betareg requires no 0s or 1s
koffset = 0.01
percent2 <- adj.percent
percent2[adj.percent == 0] = koffset;
percent2[adj.percent == 1] = 1 - koffset;
dataP2$percent2 <- percent2;

data.use<-dataP2

N = length(data.use$percent2)
n.Study <- length(unique(data.use$Study)) #number of studies
Studyint<-as.integer(unclass(factor(data.use$Study)))
phi = data.use$Total.N

stan.data<-list(N = N, percent = data.use$percent2, Ind = data.use$Pre.Ind.Rise, phi = phi, S = n.Study, Study = Studyint)
params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")
# mod=stan(file="MetaRisk2 RSTAN betareg 2b.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=3,iter=8000, save_warmup = FALSE,
#          init = init.fn, control=list(adapt_delta = 0.9, max_treedepth = 15))

load("2pre_khi.rds")

params.to.monitor2=c("mu","beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 
#ggsave("Fig S1a koffset 01.png",width=8,height=5.5,unit="in",dpi="print")
#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
```

```{r main proportional analysis with smaller koffset, cache=TRUE}
#Bayesian stan model proportional and weighted
#betareg requires no 0s or 1s
koffset = 0.0001
percent2 <- adj.percent
percent2[adj.percent == 0] = koffset;
percent2[adj.percent == 1] = 1 - koffset;
dataP2$percent2 <- percent2;

data.use<-dataP2

N = length(data.use$percent2)
n.Study <- length(unique(data.use$Study)) #number of studies
Studyint<-as.integer(unclass(factor(data.use$Study)))
phi = data.use$Total.N

stan.data<-list(N = N, percent = data.use$percent2, Ind = data.use$Pre.Ind.Rise, phi = phi, S = n.Study, Study = Studyint)
params.to.monitor=c("mu","beta","y_rep","stu","sigma_stu", "eta","log_lik")
# mod=stan(file="MetaRisk2 RSTAN betareg 2b.stan",data=stan.data,pars=params.to.monitor,
#          chains = 3, warmup=5000, cores=3,iter=8000, save_warmup = FALSE,
#          init = init.fn, control=list(adapt_delta = 0.9, max_treedepth = 15))
load("2pre_klo.rds")

params.to.monitor2=c("mu","beta")#
sumx = summary(mod,probs=c(.025,0.975), digits=4, pars=params.to.monitor2) 
sumx$summary

#checks
traceplot(mod,pars=params.to.monitor2,inc_warmup=FALSE)

pp_check(
  stan.data$percent,
  rstan::extract(mod, par = 'y_rep')$y_rep[1:100, ], 
  fun = 'dens_overlay'
) 
#ggsave("Fig S1c koffset 0001.png",width=8,height=5.5,unit="in",dpi="print")
#calculate loo
# log_lik_1 <- extract_log_lik(mod, merge_chains = FALSE)
# r_eff <- relative_eff(exp(log_lik_1), cores = 6)
# loo.mod <- loo(log_lik_1, r_eff = r_eff, cores = 6)
loo.mod # 
#
```

```{r Fig 5, cache=TRUE}
#---------------------------------------------------------------------------------------
#hi offset
load("2pre_khi.rds") #all non-proportionate analysis
modx = mod

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_bigk = pred.reg.quant[2,],
                          low_line_bigk = pred.reg.quant[1,],
                          hi_line_bigk = pred.reg.quant[3,])
#---------------------------------------------------------------------------------------
#small offset
load("2pre_klo.rds") #all non-proportionate analysis
modx = mod

#Calculate estimates
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_lok = pred.reg.quant[2,]
pred.reg.df$low_line_lok = pred.reg.quant[1,]
pred.reg.df$hi_line_lok = pred.reg.quant[3,]
#---------------------------------------------------------------------------------------
#just right offset
load("2pre_lowb.rds") 
modx = mod
posterior=as.data.frame(modx); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_base = pred.reg.quant[2,]
pred.reg.df$low_line_base = pred.reg.quant[1,]
pred.reg.df$hi_line_base= pred.reg.quant[3,]

Fig5<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_bigk,ymax=hi_line_bigk),alpha=.4,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_bigk),size=1.5,color="#154c8e")+
      geom_ribbon(aes(x=P.Ind,ymin=low_line_bigk,ymax=hi_line_lok),alpha=.4,fill="darkgreen")+
  geom_line(aes(x=P.Ind,y=mean_line_lok),size=1.5,color="darkgreen")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig5

#ggsave("Fig S2 preind dfrt offsets.png",width=8,height=5.5,unit="in",dpi="print")
```

#Offset analysis Changing the offset for zeros has a minor effect on results, with slightly higher predictions for a larger offset relative to baseline and lower predictions for a lower offset than baseline. However, the credible intervals all overlap.

```{r gaussian logit analysis, cache=TRUE}
#Bayesian stan model proportional and weighted
#betareg requires no 0s or 1s
dataP2$logit<-logit(adj.percent)
dataP2$logit[dataP2$adj.percent == 0] = log((.5)/((Total.N[dataP2$adj.percent == 0] + 1)-(.5)))
dataP2$logit[dataP2$adj.percent == 1] = log((Total.N[dataP2$adj.percent == 1] + .5)/((Total.N[dataP2$adj.percent == 1] + 1)-(Total.N[dataP2$adj.percent == 1] + .5))) #original koffset method

hist(dataP2$logit)

vari<-(adj.percent * (1 - adj.percent))/Total.N

betam<-rbind(cbind(-50,0),cbind(0,0))
betav<-rbind(cbind(1,0),cbind(0,100))

prior <- list(B = list(mu = betam, V = betav), R = list(V = 1, nu = 0.002), G = list(G1=list(V = 1, nu=.002))) #standard weakly informative priors, except for intercept
 model.log<-MCMCglmm(logit~Pre.Ind.Rise,random=~Study, mev=vari,nitt=50000,data=dataP2, prior=prior, burnin=40000,thin =10) 
#load("1pre ind logit.rds")
summary(model.log)

#save(model.log,file = "2pre ind logit 2.rds")
```

```{r Fig 6, cache=TRUE}
load("2pre ind logit 2.rds") #all non-proportionate analysis
posterior <- as.data.frame(model.log$Sol)
pred.reg = sapply(1:1000, FUN = function(x) {posterior[x,1] + posterior$Pre.Ind.Rise[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df <- data.frame(x = P.Ind,
                          mean_line_log = pred.reg.quant[2,],
                          low_line_log = pred.reg.quant[1,],
                          hi_line_log = pred.reg.quant[3,])

load("2pre_lowb.rds")
mod2 = mod
posterior=as.data.frame(mod2); 
pred.reg = sapply(1:length(posterior$mu), FUN = function(x) {posterior$mu[x] + posterior$beta[x]*P.Ind})
pred.reg.quant = invlogit(apply(pred.reg, 1, quantile, probs = c(0.025, 0.5, 0.975),na.rm=TRUE))
pred.reg.df$mean_line_base = pred.reg.quant[2,]
pred.reg.df$low_line_base = pred.reg.quant[1,]
pred.reg.df$hi_line_base= pred.reg.quant[3,]

Fig6<-ggplot(data = pred.reg.df)+
  geom_ribbon(aes(x=P.Ind,ymin=low_line_base,ymax=hi_line_base),alpha=.7,fill="#Eabecd")+
  geom_line(aes(x=P.Ind,y=mean_line_base),size=1.5,color="#941C2F")+
    geom_ribbon(aes(x=P.Ind,ymin=low_line_log,ymax=hi_line_log),alpha=.5,fill="#Bfccdc")+
  geom_line(aes(x=P.Ind,y=mean_line_log),size=1.5,color="#154c8e")+
  xlab("Pre-industrial rise in temperature (C)") + ylab("Predicted extinction risk")+
  theme_classic()+
  theme(axis.title=element_text(size=18),title=element_text(size=20),axis.text = element_text(size=16))+
  guides(size=F)
Fig6

#ggsave("Fig S4 preind orig vs new.png",width=8,height=5.5,unit="in",dpi="print")
```

#Comparing baseline analysis (red) with the original Gaussian analysis of logits (blue) with faded 95% credible intervals The two analyses overlap, with a lower result for the baseline analysis.

# Variation explained

```{r, var explained, warnings = F}
#After Gelman 2019 R2 for Bayesian
#
#Load model and beta matrix - check if mu is modeled separately
load("2pre_lowb.rds")
posterior=as.data.frame(mod); #caution mu/beta model not just beta
betamat <- (model.matrix(~Pre.Ind.Rise,data=data.use)) 

#Variables and matrices
S = 9000; #samples
K = ncol(betamat); #factors
p.mat <- as.matrix(posterior[,1:K])
y = dataP2$percent2 
y.mat = t(matrix(rep(y,S), nrow = N, ncol = S))
y.mean <- mean(y)

#Calculate y.pred for fixed effects only
y.pred <- matrix(rep(NA, N*S), nrow = S, ncol = N)
theta <- y.pred
for (i in 1:N) {
      theta[,i] = invlogit(p.mat %*% betamat[i,])#rows = samples, cols = i
      y.pred[,i] = (theta[,i] * data.use$Total.N[i])/(theta[,i] * data.use$Total.N[i] + (1-theta[,i]) * data.use$Total.N[i])
}

#Calcluate residual variance
res.f = y.mat - y.pred    
RSS.f = rowSums((res.f)^2)
res.v.f = 1/(N -1) * RSS.f

#Calculate fit variance
pred.v.f = 1/(N-1) * rowSums((y.pred)^2)

#Calculate R2
R2.v.f = pred.v.f/(pred.v.f + res.v.f)
cat("fixed effects R2 = ", quantile(R2.v.f,probs = c(0.025, 0.5, 0.975),na.rm = T))

#Total model With random effects
y.pred.c <-(as.matrix(posterior[,(K+1):(N+K)])) #calculated in STAN, with all RE and weightings

#Calculate residual variance
res.c = y.mat - y.pred.c    
RSS.c = rowSums((res.c)^2)
res.v.c = 1/(N-1) * RSS.c

#Calculate fit variance

pred.v.c = 1/(N-1) * rowSums(y.pred.c^2)

#Calculate full model R2
R2.v.c = pred.v.c/(pred.v.c + res.v.c)
cat("Overall model R2 = ", quantile(R2.v.c,probs = c(0.025, 0.5, 0.975),na.rm = T))

```
